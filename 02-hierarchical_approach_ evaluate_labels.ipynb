{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18abd232-1b87-4704-bab0-b003c6ed93b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This notebook evaluates the top taxonomy labels for each document by querying ChatGPT to determine if each label is a suitable fit. The results are stored as a new column in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb963c5a-33ea-4194-8c73-78bc039fec54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "543a1147-8ad5-40e1-a06e-fda1c17251cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15e99303-75d0-4539-8918-d774aac6d8b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed  \n",
    "import re  \n",
    "import pickle\n",
    "import math\n",
    "import random  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ca204b9-195f-4d2d-982c-c223e2352ef7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "conf = DataBricksDevConfig\n",
    "path_results = conf.Data.path_results\n",
    "path_taxonomy = conf.Data.path_taxonomy\n",
    "folder_name = conf.Data.folder_name\n",
    "dic_abbreviation2full = conf.taxonomy_info.dic_abbreviation2full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b30ace2-9fb5-4ee5-b56b-6941fcfd8143",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df_in = pd.read_pickle(path_results + '0_json_to_dataframe.pckl')\n",
    "    print(len(df_in))\n",
    "except Exception as e:\n",
    "    print(\"Cluster could not read the file (1- wrong cluster 2- no new json file)\",e)\n",
    "    dbutils.notebook.exit(str(e))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d90b3ac0-0bf3-42a5-ae85-afb4a63076d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Read Taxonomy from generated Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51074c44-66fb-4603-b40c-b610e1c80b7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def clean_label(label):\n",
    "    cleaned_label = label\n",
    "    for abbreviation, expansion in dic_abbreviation2full.items():\n",
    "        if cleaned_label.startswith(abbreviation):\n",
    "            cleaned_label = cleaned_label.replace(abbreviation, expansion)\n",
    "    return cleaned_label  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8afa521-3fba-440f-8712-d73cf4f7c992",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(path_taxonomy + 'dic_taxonomy_embeddings.pickle', 'rb') as file:\n",
    "    dic_taxonomy = pickle.load(file)\n",
    "#1\n",
    "dic_taxonomy_id2label = {dic_taxonomy[label]['id']:label for label in dic_taxonomy.keys()}\n",
    "#2   \n",
    "labels_all = list(dic_taxonomy.keys())  \n",
    "#3  \n",
    "root_labels = []\n",
    "for k,v in dic_taxonomy.items():\n",
    "    if len(v['parent_label'])==0:\n",
    "        root_labels.append(k)\n",
    "print(root_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a25dc2a1-c967-40f6-8594-4db363bb2ae6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# required functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "157ecf8e-0ad9-4c5a-9284-e46b842c7501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Set up the ChatGPT Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3625d71f-aecf-48d0-8ce7-cc902f3a9a9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt_system = \"\"\"You are an AI trained to evaluate the relevance of multiple labels for a given SSRN pre-print document. For this task, you will receive the document's title, keywords, abstract, and a list of labels. Each label in the list has an ID, a name and description. Your task is to determine which labels  are the best fit for the document. A label fits well if the document's main focus aligns with the area the label describes. Your output should be a concise JSON object containing a list, 'best_labels', which only includes the ID of labels that best fit the document.\"\"\" \n",
    "\n",
    "def F_prompt (document, labels) :   \n",
    "    labels_txt = ''\n",
    "    for label in labels:\n",
    "        label_id = dic_taxonomy[label]['id']\n",
    "        if len(dic_taxonomy[label]['description_cleaned'])>0:\n",
    "            description = dic_taxonomy[label]['description_cleaned']\n",
    "        else:\n",
    "            description = dic_taxonomy[label]['description_generated']\n",
    "        labels_txt += f\"\"\"\n",
    "        ID= '{label_id}'\n",
    "        name= '{clean_label(label)}'\n",
    "        description= '{description}'\n",
    "        \"\"\"\n",
    "    prompt = f\"\"\"given document:\n",
    "    'title'= '{document['title']}',\n",
    "    'abstract'= '{document['abstract']}'\n",
    "    'keywords'= '{document['keywords']}'\n",
    "\n",
    "    Labels:{labels_txt}\n",
    "    \"\"\"\n",
    "    return(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2eb6c867-2c03-4508-aa7e-78657f5842fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "json_format = [\n",
    "    {\n",
    "        \"name\": \"check_relevancy\",\n",
    "        \"description\": \"check relevancy\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"best_labels\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"description\": \"list of IDs of baest labels\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"integer\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"best_labels\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "def F_prompt_GPT(document,labels):\n",
    "    message_user = F_prompt(document, labels)\n",
    "    message_system = prompt_system\n",
    "    return(generate_openai_response( message_user, message_system, json_format,max_tokens=2000),message_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc76452e-9fd1-4319-8f3f-8eef4273a491",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ASK GPT In parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bb6b19a-5083-487a-b634-4b5cf255ddc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_in['labels_hierarchical_approach'] = [[] for _ in range(len(df_in))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2661c1c3-14a8-4a61-a002-4082b2954904",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for i_row, doc_tmp in df_in.iloc[:].iterrows():\n",
    "    print()\n",
    "    history_labels=[]\n",
    "    history_prompts=[]\n",
    "    selected_labels_final = []\n",
    "    selected_labels_intermediate = root_labels\n",
    "\n",
    "    while len(selected_labels_intermediate)>0 :\n",
    "\n",
    "        # handle the first 100 labels:\n",
    "        print(i_row , len(selected_labels_intermediate))\n",
    "        try:\n",
    "            GPT_selected_labels, prompt_ = F_prompt_GPT(doc_tmp, selected_labels_intermediate[0:100])\n",
    "        except:\n",
    "            print('Dev-GPT4o')\n",
    "            GPT_selected_labels, prompt_ = F_prompt_GPT(doc_tmp, selected_labels_intermediate[0:100])\n",
    "\n",
    "        GPT_selected_labels = GPT_selected_labels['best_labels']\n",
    "        GPT_selected_labels = [dic_taxonomy_id2label[l] for l in GPT_selected_labels]\n",
    "        history_prompts.append(prompt_)\n",
    "        # handle the other labels:   \n",
    "        if len (selected_labels_intermediate)>100:\n",
    "            print(i_row ,  len(selected_labels_intermediate), \"splited in two parts\")\n",
    "\n",
    "            GPT_selected_labels2, prompt_ = F_prompt_GPT(doc_tmp, selected_labels_intermediate[100:])\n",
    "            \n",
    "            GPT_selected_labels2 = GPT_selected_labels2['best_labels']\n",
    "            GPT_selected_labels2 = [dic_taxonomy_id2label[l] for l in GPT_selected_labels2]\n",
    "\n",
    "            GPT_selected_labels.extend(GPT_selected_labels2)\n",
    "            history_prompts.append(prompt_)\n",
    "\n",
    "\n",
    "        selected_labels_intermediate = []\n",
    "        history_labels.append(GPT_selected_labels)\n",
    "        for l in GPT_selected_labels:\n",
    "            if l in labels_all:\n",
    "                if len(dic_taxonomy[l]['children_labels'])==0:\n",
    "                    selected_labels_final.append(l)\n",
    "                else:\n",
    "\n",
    "                    selected_labels_intermediate.extend(dic_taxonomy[l]['children_labels'])\n",
    "            else:\n",
    "                print(f'label <{l}> does not exist in the taxonomy')\n",
    "\n",
    "    df_in.at[i_row,'labels_hierarchical_approach'] = selected_labels_final\n",
    "    print('-->', len(selected_labels_final))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b035a997-5968-4d83-b1f0-8419300a3bb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2321c8d-afb6-49fa-96dc-fe2d3f131a3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_in.to_pickle(path_results + f'1_hierarchical_label_selection.pckl')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01-hierarchical_approach",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
