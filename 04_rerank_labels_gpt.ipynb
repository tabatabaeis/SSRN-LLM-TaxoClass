{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18abd232-1b87-4704-bab0-b003c6ed93b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This notebook evaluates the top taxonomy labels for each document by querying ChatGPT to determine if each label is a suitable fit. The results are stored as a new column in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb963c5a-33ea-4194-8c73-78bc039fec54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "543a1147-8ad5-40e1-a06e-fda1c17251cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15e99303-75d0-4539-8918-d774aac6d8b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed  \n",
    "import re  \n",
    "import pickle\n",
    "import math\n",
    "from collections import Counter\n",
    "import random  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ca204b9-195f-4d2d-982c-c223e2352ef7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "conf = DataBricksDevConfig\n",
    "path_results = conf.Data.path_results\n",
    "path_taxonomy = conf.Data.path_taxonomy\n",
    "folder_name = conf.Data.folder_name\n",
    "dic_abbreviation2full = conf.taxonomy_info.dic_abbreviation2full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b30ace2-9fb5-4ee5-b56b-6941fcfd8143",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df_in = pd.read_pickle(path_results + '2_embedding_similarity_results.pckl')\n",
    "except Exception as e:\n",
    "    dbutils.notebook.exit(str(e))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d90b3ac0-0bf3-42a5-ae85-afb4a63076d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Read Taxonomy from generated Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51074c44-66fb-4603-b40c-b610e1c80b7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def clean_label(label): \n",
    "    cleaned_label = label\n",
    "    for abbreviation, expansion in dic_abbreviation2full.items():\n",
    "        if cleaned_label.startswith(abbreviation):\n",
    "            cleaned_label = cleaned_label.replace(abbreviation, expansion)\n",
    "    return cleaned_label  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8afa521-3fba-440f-8712-d73cf4f7c992",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(path_taxonomy + 'dic_taxonomy_embeddings.pickle', 'rb') as file:\n",
    "    dic_taxonomy = pickle.load(file)\n",
    "dic_taxonomy_id2label = {dic_taxonomy[label]['id']:label for label in dic_taxonomy.keys()} \n",
    "labels_all = list(dic_taxonomy.keys())   \n",
    "root_labels = []\n",
    "for k,v in dic_taxonomy.items():\n",
    "    if len(v['parent_label'])==0:\n",
    "        root_labels.append(k)\n",
    "print(root_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a25dc2a1-c967-40f6-8594-4db363bb2ae6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# required functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "157ecf8e-0ad9-4c5a-9284-e46b842c7501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Set up the ChatGPT Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3625d71f-aecf-48d0-8ce7-cc902f3a9a9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "prompt_system_template = \"\"\"You are an AI assistant helping me to find the conceptual similarity scores between an SSRN article and a list of {} labels.   \n",
    "  \n",
    "Please ensure the following:  \n",
    "  \n",
    "- Return a score for each label. \n",
    "- ensure there are {} scores in total\n",
    "- Ensure the scores are varied and accurately represent the level of similarity, rather than scoring a large percentage of labels the same.  \n",
    "- Consider the main theme of the article and the specific context in which keywords are used.  \n",
    "- Do not assign high similarity scores to labels that are only tangentially related or share a few keywords with the article. The focus should be on the overall subject matter of the article.  \n",
    "- Scores should have two decimal points for greater precision.  \n",
    "  \n",
    "The output should be a JSON object named \"scores\" that contains a list of {} tuples. Each tuple should contain a label ID and a relevancy score between 0.01 and 1.00, indicating the level of relevancy between the label and the given document.  \n",
    "\"\"\"\n",
    "\n",
    "def F_prompt (document, labels) :\n",
    "\n",
    "\n",
    "   \n",
    "    labels_txt = ''\n",
    "    for label in labels:\n",
    "        label_id = dic_taxonomy[label]['id']\n",
    "        if len(dic_taxonomy[label]['description_cleaned'])>0:\n",
    "            description = dic_taxonomy[label]['description_cleaned']\n",
    "        else:\n",
    "            description = dic_taxonomy[label]['description_generated']\n",
    "        \n",
    "        if len(description) <2:\n",
    "            description = \"not available\"\n",
    "        description = description.replace('\\r',' ').replace('\\n\\n','  ')\n",
    "\n",
    "        labels_txt += f\"\"\"\n",
    "        ID= {label_id}\n",
    "        name= '{clean_label(label)}'\n",
    "        description= '{description}'\n",
    "        \"\"\"\n",
    "\n",
    "    label_ids  = [dic_taxonomy[label]['id'] for label in labels]\n",
    "    prompt = f\"\"\"given document:\n",
    "    'title'= '{document['title']}',\n",
    "    'abstract'= '{document['abstract']}'\n",
    "    'keywords'= '{document['keywords']}'\n",
    "\n",
    "    Labels:{labels_txt}\n",
    "\n",
    "\n",
    "    \n",
    "    Please provide a score for each label, {len(labels)} scores in total. Ensure you include all of these label IDs:\n",
    "    {label_ids}\n",
    "    \"\"\"\n",
    "    return(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2eb6c867-2c03-4508-aa7e-78657f5842fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "json_format =[  \n",
    "    {  \n",
    "        \"name\": \"check_relevancy\",  \n",
    "        \"description\": \"check relevancy\",  \n",
    "        \"parameters\": {  \n",
    "            \"type\": \"object\",  \n",
    "            \"properties\": {  \n",
    "                \"labels_scores\": {  \n",
    "                    \"type\": \"array\",  \n",
    "                    \"description\": \"list of tuples containing label ID and relevancy score\",  \n",
    "                    \"items\": {  \n",
    "                        \"type\": \"object\",  \n",
    "                        \"properties\": {  \n",
    "                            \"label_id\": {  \n",
    "                                \"type\": \"integer\",  \n",
    "                                \"description\": \"label ID\"  \n",
    "                            },  \n",
    "                            \"relevancy_score\": {  \n",
    "                                \"type\": \"number\",  \n",
    "                                \"description\": \"relevancy score\",  \n",
    "                                \"minimum\": 0.01,  \n",
    "                                \"maximum\": 1.00  \n",
    "                            }  \n",
    "                        },  \n",
    "                        \"required\": [\"label_id\", \"relevancy_score\"]  \n",
    "                    }  \n",
    "                }  \n",
    "            },  \n",
    "            \"required\": [\"labels_scores\"]  \n",
    "        }  \n",
    "    }  \n",
    "]  \n",
    "\n",
    "\n",
    "\n",
    "def F_prompt_GPT(document,labels):\n",
    "    message_user = F_prompt(document, labels)\n",
    "    L = len(labels)\n",
    "    message_system = prompt_system_template.format(L,L,L)\n",
    "\n",
    "    return(generate_openai_response(message_user, message_system, json_format, max_tokens=2000),message_user,message_system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d0d6d06-f774-4e70-94bd-3ab11d91854e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Mathermatical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "255ed5bd-e867-4051-bb66-726bfcaca72a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def F_just_leaf(numbers_original):\n",
    "    return (numbers_original[0])\n",
    "\n",
    "def F_mean(numbers_original):\n",
    "    return(np.mean(numbers_original))\n",
    "\n",
    "def F_mean_leaf_parent(numbers_original):\n",
    "    return(np.mean(numbers_original[:2]))\n",
    "\n",
    "def F_harmonic_mean(numbers_original):\n",
    "    numbers = numbers_original.copy()\n",
    "    n = len(numbers)\n",
    "    if any(x == 0 for x in numbers):\n",
    "        return 0    \n",
    "    return n / sum(1 / x for x in numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b963600a-98b2-4e24-8fc3-c3770390e556",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculate_entropy(data):\n",
    "    # Count the frequency of each unique number in the list\n",
    "    frequency = Counter(data)\n",
    "    \n",
    "    # Calculate the total number of elements\n",
    "    total_count = len(data)\n",
    "    \n",
    "    # Calculate the entropy\n",
    "    entropy = 0\n",
    "    for count in frequency.values():\n",
    "        # Calculate the probability of each unique number\n",
    "        probability = count / total_count\n",
    "        \n",
    "        # Update the entropy sum\n",
    "        entropy -= probability * math.log2(probability)\n",
    "    \n",
    "    return entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc76452e-9fd1-4319-8f3f-8eef4273a491",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ASK GPT In parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0a01fc5-8fda-48a1-87ae-d99adc1ff656",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "n_initial = 40\n",
    "F_functions = [F_just_leaf, F_mean, F_mean_leaf_parent, F_harmonic_mean]\n",
    "for F_mathematical in F_functions :\n",
    "    df_in[f'labels_RankRerank_approach_{F_mathematical.__name__[2:]}'] = [{} for _ in range(len(df_in))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dac89c6-cf32-4c92-86b0-2a43fc9c733c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "A"
    }
   },
   "outputs": [],
   "source": [
    "for i_doc,doc_tmp in df_in.iloc[:].iterrows():\n",
    "    print(i_doc, end = ' . ')\n",
    "    # getting the inital labels\n",
    "    leave_labels = doc_tmp['labels_BiEncoder'][0:n_initial]\n",
    "    leave_labels_temp = leave_labels.copy()\n",
    "    # getting the inital labels + their parrents\n",
    "    flag_bool = True\n",
    "    while flag_bool:\n",
    "        flag_bool = False\n",
    "        L = len(leave_labels_temp)  \n",
    "        print(L, end = ' --> ')\n",
    "        for i_label  in range(len(leave_labels_temp)):\n",
    "            label = leave_labels_temp[i_label]\n",
    "            label_parent = dic_taxonomy[label]['parent_label']\n",
    "            if label_parent != \"\":\n",
    "                if label_parent in leave_labels_temp:\n",
    "                    pass\n",
    "                else:\n",
    "                    leave_labels_temp.append(dic_taxonomy[label]['parent_label'])\n",
    "                    flag_bool = True\n",
    "\n",
    "    # Ask GPT to score them\n",
    "\n",
    "    GPT_scores , prompt_user_, system_message_ = F_prompt_GPT(doc_tmp, leave_labels_temp)\n",
    "         \n",
    "    print(f' GPT gave back  {len(GPT_scores[\"labels_scores\"])} answers' , end = ' >> ')\n",
    "    dic_GPT_scores = {item['label_id']:item['relevancy_score'] for item in GPT_scores['labels_scores']}\n",
    "    print('entropy:', calculate_entropy(list(dic_GPT_scores.values())), end = ' >> ')\n",
    "    print('Mathematical Functions',)\n",
    "\n",
    "\n",
    "    # Mathematical functions\n",
    "    F_functions = [F_just_leaf, F_mean, F_mean_leaf_parent, F_harmonic_mean]\n",
    "    for F_mathematical in F_functions :\n",
    "        dic_function = {}\n",
    "        for label_leave in leave_labels:\n",
    "            label_ID = dic_taxonomy[label_leave]['id']\n",
    "            parental_scores = []\n",
    "            while label_ID != \"\":\n",
    "                parental_scores.append(dic_GPT_scores[label_ID])\n",
    "                label_ID = dic_taxonomy[dic_taxonomy_id2label[ label_ID]]['parent_id']\n",
    "\n",
    "            \n",
    "            dic_function[label_leave] = F_mathematical(parental_scores)\n",
    "        dic_function_sorted = list(sorted(dic_function.items(), key=lambda item: item[1], reverse=True)  )\n",
    "        df_in.at[i_doc,f'labels_RankRerank_approach_{F_mathematical.__name__[2:]}'] = [item[0] for item in dic_function_sorted]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b035a997-5968-4d83-b1f0-8419300a3bb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2321c8d-afb6-49fa-96dc-fe2d3f131a3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_in.to_pickle(path_results + '3-RankRerank.pckl')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03- RankRerank",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
