{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18abd232-1b87-4704-bab0-b003c6ed93b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This notebook evaluates the top taxonomy labels for each document by querying ChatGPT to determine if each label is a suitable fit. The results are stored as a new column in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb963c5a-33ea-4194-8c73-78bc039fec54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "543a1147-8ad5-40e1-a06e-fda1c17251cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15e99303-75d0-4539-8918-d774aac6d8b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed  \n",
    "import re  \n",
    "import pickle\n",
    "import math\n",
    "from collections import Counter\n",
    "import random  \n",
    "import json  \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ca204b9-195f-4d2d-982c-c223e2352ef7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "conf = DataBricksDevConfig\n",
    "\n",
    "path_results = conf.Data.path_results\n",
    "path_taxonomy = conf.Data.path_taxonomy\n",
    "folder_name = conf.Data.folder_name\n",
    "dic_abbreviation2full = conf.taxonomy_info.dic_abbreviation2full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b30ace2-9fb5-4ee5-b56b-6941fcfd8143",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df_in = pd.read_pickle(path_results + '5-PrpposedApproach(ablation2).pckl')\n",
    "    print(len(df_in))\n",
    "    df_in.head(2)\n",
    "except Exception as e:\n",
    "    print(\"Cluster could not read the file (1- wrong cluster 2- no new json file)\",e)\n",
    "    dbutils.notebook.exit(str(e))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d90b3ac0-0bf3-42a5-ae85-afb4a63076d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Read Taxonomy from generated Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8afa521-3fba-440f-8712-d73cf4f7c992",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(path_taxonomy + 'dic_taxonomy_embeddings.pickle', 'rb') as file:\n",
    "    dic_taxonomy = pickle.load(file)\n",
    "#1\n",
    "dic_taxonomy_id2label = {dic_taxonomy[label]['id']:label for label in dic_taxonomy.keys()}\n",
    "#2   \n",
    "labels_all = list(dic_taxonomy.keys())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ead78123-2b66-49e2-8780-3a3197b46989",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def clean_label(label):\n",
    "    cleaned_label = label\n",
    "    for abbreviation, expansion in dic_abbreviation2full.items():\n",
    "        if cleaned_label.startswith(abbreviation):\n",
    "            cleaned_label = cleaned_label.replace(abbreviation, expansion)\n",
    "    return cleaned_label  \n",
    "\n",
    "\n",
    "for k,v in dic_taxonomy.items():\n",
    "    dic_taxonomy[k]['cleaned_name']= clean_label(k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a25dc2a1-c967-40f6-8594-4db363bb2ae6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3625d71f-aecf-48d0-8ce7-cc902f3a9a9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt_system =\"\"\"You are an AI trained to evaluate the relevance of multiple labels for a given SSRN pre-print document, and select top 5 labels that best fit the document. For this task, you will receive the document's title, keywords, abstract, and a list of labels. Each label in the list has an ID, name, description. Your task is to determine which labels are the best fit for the document. A label fits well ifThe document's main focus aligns with the area the label describes.  \n",
    "Please return the IDs of the top 5 labels that best fit the given document.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def F_prompt (document, labels) :\n",
    "    labels_txt = ''\n",
    "    for label in labels:\n",
    "        label_id = dic_taxonomy[label]['id']\n",
    "        if len(dic_taxonomy[label]['description_cleaned'])>0:\n",
    "            description = dic_taxonomy[label]['description_cleaned']\n",
    "        else:\n",
    "            description = dic_taxonomy[label]['description_generated']\n",
    "        description = description.replace('\\r',' ').replace('\\n\\n','  ')\n",
    "\n",
    "        labels_txt += f\"\"\"\n",
    "        ID= {label_id}\n",
    "        name= '{clean_label(label)}'\n",
    "        description= '{description}'\n",
    "        \"\"\"\n",
    "\n",
    "    label_ids  = [dic_taxonomy[label]['id'] for label in labels]\n",
    "    prompt = f\"\"\"given document:\n",
    "    'title'= '{document['title']}',\n",
    "    'abstract'= '{document['abstract']}'\n",
    "    'keywords'= '{document['keywords']}'\n",
    "\n",
    "    Labels:{labels_txt}\n",
    "    \"\"\"\n",
    "    return(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2eb6c867-2c03-4508-aa7e-78657f5842fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "json_format = [\n",
    "    {\n",
    "        \"name\": \"check_relevancy\",\n",
    "        \"description\": \"check relevancy\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"best_labels\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"description\": \"list of IDs of top 5 best labels\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"integer\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"best_labels\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "def F_prompt_GPT(document, labels):\n",
    "    message_user = F_prompt(document, labels)\n",
    "    message_system = prompt_system\n",
    "    return(generate_openai_response( message_user, message_system, json_format, max_tokens=2000),message_system ,message_user )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc76452e-9fd1-4319-8f3f-8eef4273a491",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ASK GPT In parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03d7085d-bfad-4bb0-b59f-0d36b910de8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns_to_check = ['labels_hierarchical_approach', 'labels_ShortenTaxonomy_approach','labels_Proposed_approach', 'labels_Proposed_approach_ablation1', 'labels_Proposed_approach_ablation2']\n",
    "\n",
    "for col in columns_to_check :\n",
    "    df_in[col+'_5labels'] = [[] for _ in range(len(df_in))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dac89c6-cf32-4c92-86b0-2a43fc9c733c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "A"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i_doc,doc_tmp in df_in.iloc[:].iterrows():\n",
    "    print(i_doc, end = ', ')\n",
    "    for col in columns_to_check:\n",
    "        print(col, end = ' ')\n",
    "        # call GPT in parallel\n",
    "        selected_labels = doc_tmp[col]\n",
    "        # print(i_doc)\n",
    "        if len(selected_labels) > 5 :\n",
    "            print(len(selected_labels) , end= ' -->')\n",
    "            GPT_answer_labels, message_system_ ,message_user_  = F_prompt_GPT(doc_tmp,selected_labels)\n",
    "            selected_label_IDs = GPT_answer_labels['best_labels']\n",
    "            if len(selected_label_IDs)!=5:\n",
    "                print(len(selected_label_IDs), 'WHAT?')\n",
    "            selected_labels = [dic_taxonomy_id2label[id] for id in selected_label_IDs]\n",
    "        print()\n",
    "        df_in.at[i_doc,col+'_5labels'] = selected_labels\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ed7a2b1-5f49-480e-869e-234c4c4476ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# To fix the cases that GPT did not resolve\n",
    "\n",
    "Dev-GPT4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88c35c2f-d68a-46d3-8421-9a175641cc35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for i_doc,doc_tmp in df_in.iloc[:].iterrows():\n",
    "    print(i_doc, end = ', ')\n",
    "    for col in columns_to_check:\n",
    "        print(col, end = ' ')\n",
    "        # call GPT in parallel\n",
    "        selected_labels = doc_tmp[col+'_5labels']\n",
    "        # print(i_doc)\n",
    "        if len(selected_labels) > 5 :\n",
    "            print(len(selected_labels) , end= ' -->')\n",
    "            GPT_answer_labels, message_system_ ,message_user_  = F_prompt_GPT(doc_tmp,selected_labels)\n",
    "            selected_label_IDs = GPT_answer_labels['best_labels']\n",
    "            if len(selected_label_IDs)!=5:\n",
    "                print(len(selected_label_IDs), 'WHAT?')\n",
    "            selected_labels = [dic_taxonomy_id2label[id] for id in selected_label_IDs]\n",
    "        print()\n",
    "        df_in.at[i_doc,col+'_5labels'] = selected_labels\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b035a997-5968-4d83-b1f0-8419300a3bb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2321c8d-afb6-49fa-96dc-fe2d3f131a3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_in.to_pickle(path_results + f'6-SelectionReduction.pckl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "badd2c4b-f33c-4fea-87b4-5e6d66eb17a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15fa80de-a0c9-4746-a54b-d36bf156f645",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9afcaeff-f02c-429c-ae9c-2754de219e53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(df_in.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fa1884d-556e-41b2-9221-236d88589635",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt  \n",
    "  \n",
    "\n",
    "# List of columns to consider (replace this with your actual list of columns)  \n",
    "columns =  ['labels_hierarchical_approach', 'labels_ShortenTaxonomy_approach','labels_Proposed_approach',\n",
    "       'labels_Proposed_approach_ablation1',\n",
    "       'labels_Proposed_approach_ablation2',\n",
    "       'labels_hierarchical_approach_5labels', 'labels_ShortenTaxonomy_approach_5labels','labels_Proposed_approach_5labels',\n",
    "       'labels_Proposed_approach_ablation1_5labels',\n",
    "       'labels_Proposed_approach_ablation2_5labels']\n",
    "  \n",
    "  \n",
    "# Create a new DataFrame with the count of items in each list  \n",
    "count_df = df_in[columns].applymap(len)  \n",
    "  \n",
    "# Plot histograms for each column  \n",
    "for column in columns:  \n",
    "    plt.figure()  \n",
    "    plt.hist(count_df[column], bins=range(1, count_df[column].max() + 2), align='left', rwidth=0.8)  \n",
    "    plt.title(f'Histogram of Number of Items in {column}')  \n",
    "    plt.xlabel('Number of Items')  \n",
    "    plt.ylabel('Frequency')  \n",
    "    plt.grid(axis='y', alpha=0.75)  \n",
    "    plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b62ae879-008e-4842-8124-ca61df89f429",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "06-SelectionReduction",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
