{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18abd232-1b87-4704-bab0-b003c6ed93b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This notebook evaluates the top taxonomy labels for each document by querying ChatGPT to determine if each label is a suitable fit. The results are stored as a new column in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb963c5a-33ea-4194-8c73-78bc039fec54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "543a1147-8ad5-40e1-a06e-fda1c17251cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15e99303-75d0-4539-8918-d774aac6d8b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed  \n",
    "import re  \n",
    "import pickle\n",
    "import math\n",
    "from collections import Counter\n",
    "import random  \n",
    "import json  \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ca204b9-195f-4d2d-982c-c223e2352ef7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "conf = DataBricksDevConfig\n",
    "\n",
    "path_results = conf.Data.path_results\n",
    "path_taxonomy = conf.Data.path_taxonomy\n",
    "folder_name = conf.Data.folder_name\n",
    "dic_abbreviation2full = conf.taxonomy_info.dic_abbreviation2full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b30ace2-9fb5-4ee5-b56b-6941fcfd8143",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df_in = pd.read_pickle(path_results + '6-SelectionReduction.pckl')\n",
    "    print(len(df_in))\n",
    "    df_in.head(2)\n",
    "except Exception as e:\n",
    "    print(\"Cluster could not read the file (1- wrong cluster 2- no new json file)\",e)\n",
    "    dbutils.notebook.exit(str(e))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d90b3ac0-0bf3-42a5-ae85-afb4a63076d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Read Taxonomy from generated Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8afa521-3fba-440f-8712-d73cf4f7c992",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(path_taxonomy + 'dic_taxonomy_embeddings.pickle', 'rb') as file:\n",
    "    dic_taxonomy = pickle.load(file)\n",
    "#1\n",
    "dic_taxonomy_id2label = {dic_taxonomy[label]['id']:label for label in dic_taxonomy.keys()}\n",
    "#2   \n",
    "labels_all = list(dic_taxonomy.keys())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ead78123-2b66-49e2-8780-3a3197b46989",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def clean_label(label):\n",
    "    # return((label+''))    \n",
    "    cleaned_label = label\n",
    "    for abbreviation, expansion in dic_abbreviation2full.items():\n",
    "        # if abbreviation in cleaned_label:\n",
    "        if cleaned_label.startswith(abbreviation):\n",
    "            cleaned_label = cleaned_label.replace(abbreviation, expansion)\n",
    "    return cleaned_label  \n",
    "\n",
    "\n",
    "for k,v in dic_taxonomy.items():\n",
    "    dic_taxonomy[k]['cleaned_name']= clean_label(k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a25dc2a1-c967-40f6-8594-4db363bb2ae6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2eb6c867-2c03-4508-aa7e-78657f5842fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def F_select_random_items( labels):\n",
    "    if len(labels) <= 5:\n",
    "        return labels\n",
    "    else:\n",
    "        return random.sample(labels, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc76452e-9fd1-4319-8f3f-8eef4273a491",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ASK GPT In parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03d7085d-bfad-4bb0-b59f-0d36b910de8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns_to_check = ['labels_Proposed_approach']\n",
    "for col in columns_to_check :\n",
    "    df_in[col+'_ablation3_5labels'] = [[] for _ in range(len(df_in))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dac89c6-cf32-4c92-86b0-2a43fc9c733c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "A"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for i_doc,doc_tmp in df_in.iloc[:].iterrows():\n",
    "    print(i_doc, end = ', ')\n",
    "    for col in columns_to_check:\n",
    "        print(col, end = ' ')\n",
    "        # call GPT in parallel\n",
    "        selected_labels = doc_tmp[col]\n",
    "        # print(i_doc)\n",
    "        if len(selected_labels) > 5 :\n",
    "            selected_labels = F_select_random_items(selected_labels)\n",
    "            \n",
    "        df_in.at[i_doc,col+'_ablation3_5labels'] = selected_labels\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b035a997-5968-4d83-b1f0-8419300a3bb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2321c8d-afb6-49fa-96dc-fe2d3f131a3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_in.to_pickle(path_results + f'6-SelectionReduction_ablation3.pckl')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "06.1- ablationC: Random Reduction",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
